{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa0ce8e-bae2-4eb9-ba51-d8fb5a46a066",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torch_geometric networkx numpy scipy scikit-learn xgboost tqdm GraphRicciCurvature\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "mutag_hks_forman_mlp.py\n",
    "\n",
    "Pipeline:\n",
    " - load MUTAG from torch_geometric.TUDataset\n",
    " - convert graphs to networkx with atomic_number node attribute\n",
    " - compute HKS (multiple time scales) via Laplacian eigendecomposition\n",
    " - compute Forman-Ricci curvature via GraphRicciCurvature.FormanRicci\n",
    " - aggregate features per graph, train MLPClassifier, print metrics\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from scipy.linalg import eigh  # for symmetric eigenproblem\n",
    "from GraphRicciCurvature.FormanRicci import FormanRicci  # package: GraphRicciCurvature\n",
    "\n",
    "# ---------------- SETTINGS (one visible place to change) ----------------\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# HKS time scales (edit here)\n",
    "HKS_TIMES = np.logspace(-2, 2, 6)   # e.g., [1e-2, 1e-1, 1e0, 1e1, 1e2]; tune as needed\n",
    "\n",
    "# Laplacian type: 'combinatorial' or 'normalized'\n",
    "LAPLACIAN_TYPE = 'combinatorial'\n",
    "\n",
    "# Number of eigenpairs to use. For small graphs set None to compute all.\n",
    "NUM_EIGENPAIRS = None  # set e.g., 20 to truncate\n",
    "\n",
    "# MLP params\n",
    "MLP_HIDDEN = (100,)      # you can change to (200,100) etc.\n",
    "MLP_MAX_ITER = 500\n",
    "TEST_SIZE = 0.3\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "def graph_from_pyg_data(data):\n",
    "    \"\"\"Convert PyG Data to a networkx Graph with node attribute 'atomic_number'.\"\"\"\n",
    "    G = nx.Graph()\n",
    "    n = data.num_nodes\n",
    "    G.add_nodes_from(range(n))\n",
    "    # edges\n",
    "    edge_index = data.edge_index.numpy()\n",
    "    for u, v in edge_index.T:\n",
    "        G.add_edge(int(u), int(v))\n",
    "    # atomic numbers heuristics (same as before)\n",
    "    atomic_numbers = None\n",
    "    if hasattr(data, 'x') and data.x is not None:\n",
    "        x_np = data.x.numpy()\n",
    "        if x_np.ndim == 1 or x_np.shape[1] == 1:\n",
    "            atomic_numbers = x_np.reshape(-1)\n",
    "        else:\n",
    "            atomic_numbers = np.argmax(x_np, axis=1)\n",
    "    if atomic_numbers is None and hasattr(data, 'z'):\n",
    "        atomic_numbers = data.z.numpy().reshape(-1)\n",
    "    if atomic_numbers is None:\n",
    "        atomic_numbers = np.zeros(n, dtype=float)\n",
    "    for i, val in enumerate(atomic_numbers):\n",
    "        G.nodes[i]['atomic_number'] = float(val)\n",
    "    return G\n",
    "\n",
    "def build_laplacian_matrix(G, lap_type='combinatorial'):\n",
    "    \"\"\"Return Laplacian matrix as numpy array (n x n).\"\"\"\n",
    "    A = nx.to_numpy_array(G, nodelist=sorted(G.nodes()))\n",
    "    degs = A.sum(axis=1)\n",
    "    if lap_type == 'combinatorial':\n",
    "        D = np.diag(degs)\n",
    "        L = D - A\n",
    "    elif lap_type == 'normalized':\n",
    "        # symmetric normalized Laplacian L_sym = I - D^{-1/2} A D^{-1/2}\n",
    "        with np.errstate(divide='ignore'):\n",
    "            d_root_inv = 1.0 / np.sqrt(degs)\n",
    "        d_root_inv[np.isinf(d_root_inv)] = 0.0\n",
    "        Dri = np.diag(d_root_inv)\n",
    "        L = np.eye(A.shape[0]) - Dri @ A @ Dri\n",
    "    else:\n",
    "        raise ValueError(\"lap_type must be 'combinatorial' or 'normalized'\")\n",
    "    return L\n",
    "\n",
    "def compute_hks_for_graph(G, times=HKS_TIMES, lap_type=LAPLACIAN_TYPE, num_eigs=NUM_EIGENPAIRS):\n",
    "    \"\"\"\n",
    "    Compute HKS for each node and each time in times.\n",
    "    Returns: hks_matrix of shape (n_nodes, len(times))\n",
    "    \"\"\"\n",
    "    nodelist = sorted(G.nodes())\n",
    "    n = len(nodelist)\n",
    "    if n == 0:\n",
    "        return np.zeros((0, len(times)))\n",
    "    L = build_laplacian_matrix(G, lap_type=lap_type)\n",
    "    # eigh returns eigenvalues in ascending order for symmetric matrices\n",
    "    if num_eigs is None or num_eigs >= n:\n",
    "        # compute all eigenpairs\n",
    "        lam, phi = eigh(L)\n",
    "    else:\n",
    "        # compute smallest num_eigs eigenpairs via eigh for the full matrix then slice\n",
    "        lam_full, phi_full = eigh(L)\n",
    "        lam = lam_full[:num_eigs]\n",
    "        phi = phi_full[:, :num_eigs]\n",
    "    # ensure numerical non-negativity\n",
    "    lam = np.clip(lam, 0.0, None)\n",
    "    # compute h_t(x) = sum_i exp(-lam_i * t) * phi_i(x)^2\n",
    "    hks = np.zeros((n, len(times)))\n",
    "    # phi shape: (n, m), lam shape: (m,)\n",
    "    for ti, t in enumerate(times):\n",
    "        # compute weights w_i = exp(-lam_i * t)\n",
    "        w = np.exp(-lam * t)\n",
    "        # contribution per eigenfunction: w_i * phi[:, i]^2\n",
    "        # if phi has shape (n, m) and w shape (m,), compute (phi**2) @ w\n",
    "        hks[:, ti] = (phi ** 2) @ w\n",
    "    return hks\n",
    "\n",
    "def compute_forman_curvature_stats(G):\n",
    "    \"\"\"\n",
    "    Compute Forman-Ricci curvature on edges and aggregate statistics.\n",
    "    Uses GraphRicciCurvature.FormanRicci\n",
    "    Returns dict of aggregated stats\n",
    "    \"\"\"\n",
    "    # Make a shallow copy to avoid destroying original attributes in some contexts\n",
    "    G_copy = G.copy()\n",
    "    frc = FormanRicci(G_copy, verbose=\"ERROR\")\n",
    "    # compute_ricci_curvature will add 'formanCurvature' attributes to edges and nodes\n",
    "    frc.compute_ricci_curvature()\n",
    "    # collect edge curvatures\n",
    "    edge_vals = []\n",
    "    for u, v, d in G_copy.edges(data=True):\n",
    "        val = d.get('formanCurvature', None)\n",
    "        if val is not None:\n",
    "            edge_vals.append(float(val))\n",
    "    edge_vals = np.array(edge_vals) if len(edge_vals) > 0 else np.array([0.0])\n",
    "    # collect node curvatures (if present) otherwise compute average of incident edges\n",
    "    node_vals = []\n",
    "    for node in G_copy.nodes():\n",
    "        attr = G_copy.nodes[node].get('formanCurvature', None)\n",
    "        if attr is None:\n",
    "            # average incident edges if any\n",
    "            incident = [G_copy[u][v].get('formanCurvature', 0.0) for u, v in G_copy.edges(node)]\n",
    "            node_vals.append(np.mean(incident) if len(incident) > 0 else 0.0)\n",
    "        else:\n",
    "            node_vals.append(float(attr))\n",
    "    node_vals = np.array(node_vals) if len(node_vals) > 0 else np.array([0.0])\n",
    "    stats = {\n",
    "        'edge_mean': float(np.mean(edge_vals)),\n",
    "        'edge_std': float(np.std(edge_vals)),\n",
    "        'edge_min': float(np.min(edge_vals)),\n",
    "        'edge_max': float(np.max(edge_vals)),\n",
    "        'node_mean': float(np.mean(node_vals)),\n",
    "        'node_std': float(np.std(node_vals)),\n",
    "        'node_min': float(np.min(node_vals)),\n",
    "        'node_max': float(np.max(node_vals)),\n",
    "        'edge_pos_frac': float((edge_vals > 0).mean()),\n",
    "        'edge_neg_frac': float((edge_vals < 0).mean()),\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "def vectorize_graph(G):\n",
    "    \"\"\"\n",
    "    Compute HKS + Forman features, return 1D numpy array feature vector.\n",
    "    \"\"\"\n",
    "    # HKS\n",
    "    hks = compute_hks_for_graph(G, times=HKS_TIMES, lap_type=LAPLACIAN_TYPE, num_eigs=NUM_EIGENPAIRS)\n",
    "    if hks.size == 0:\n",
    "        # fallback for empty graph\n",
    "        hks_stats = np.zeros(3 * len(HKS_TIMES))  # mean,std,max per time\n",
    "    else:\n",
    "        # for each time, compute mean,std,max across nodes\n",
    "        means = np.mean(hks, axis=0)\n",
    "        stds = np.std(hks, axis=0)\n",
    "        maxs = np.max(hks, axis=0)\n",
    "        hks_stats = np.concatenate([means, stds, maxs])  # length 3*len(T)\n",
    "    # Forman curvature stats\n",
    "    fstats = compute_forman_curvature_stats(G)\n",
    "    forman_vec = np.array([\n",
    "        fstats['edge_mean'], fstats['edge_std'], fstats['edge_min'], fstats['edge_max'],\n",
    "        fstats['node_mean'], fstats['node_std'], fstats['node_min'], fstats['node_max'],\n",
    "        fstats['edge_pos_frac'], fstats['edge_neg_frac']\n",
    "    ], dtype=float)\n",
    "    # optional: add baseline graph features\n",
    "    n_nodes = G.number_of_nodes()\n",
    "    n_edges = G.number_of_edges()\n",
    "    avg_deg = 2.0 * n_edges / n_nodes if n_nodes > 0 else 0.0\n",
    "    # atomic-number basic stats\n",
    "    atomic_vals = np.array([G.nodes[n].get('atomic_number', 0.0) for n in sorted(G.nodes())]) if n_nodes > 0 else np.array([0.0])\n",
    "    atomic_stats = np.array([\n",
    "        atomic_vals.mean(), atomic_vals.std(), atomic_vals.min(), atomic_vals.max()\n",
    "    ], dtype=float)\n",
    "    # concatenate all\n",
    "    feat = np.concatenate([hks_stats, forman_vec, np.array([n_nodes, n_edges, avg_deg]), atomic_stats])\n",
    "    return feat\n",
    "\n",
    "def main():\n",
    "    dataset = TUDataset(root='data/TUDataset', name='MUTAG')\n",
    "    print(\"Loaded MUTAG with\", len(dataset), \"graphs.\")\n",
    "    graphs = []\n",
    "    labels = []\n",
    "    for data in dataset:\n",
    "        G = graph_from_pyg_data(data)\n",
    "        graphs.append(G)\n",
    "        labels.append(int(data.y.item()))\n",
    "    # vectorize\n",
    "    feats = []\n",
    "    for G in tqdm(graphs, desc=\"Vectorizing graphs\"):\n",
    "        feats.append(vectorize_graph(G))\n",
    "    X = np.vstack(feats)\n",
    "    y = np.array(labels)\n",
    "    print(\"Feature shape:\", X.shape)\n",
    "    # train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "    # MLP\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=MLP_HIDDEN, max_iter=MLP_MAX_ITER, random_state=RANDOM_STATE)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    y_pred = mlp.predict(X_test)\n",
    "    # for ROC AUC, need probabilities and binary classification\n",
    "    y_proba = mlp.predict_proba(X_test)[:, 1] if mlp.classes_.shape[0] > 1 else mlp.predict_proba(X_test)[:, 0]\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    bal = balanced_accuracy_score(y_test, y_pred)\n",
    "    try:\n",
    "        roc = roc_auc_score(y_test, y_proba)\n",
    "    except Exception:\n",
    "        roc = None\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Results:\")\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Balanced Accuracy:\", bal)\n",
    "    print(\"ROC AUC:\", roc)\n",
    "    print(\"Confusion matrix:\\n\", cm)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (gtda_env)",
   "language": "python",
   "name": "gtda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

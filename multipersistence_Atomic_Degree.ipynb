{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "037e3fe4-23bb-47ac-8969-208d3f9f1373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded MUTAG with 188 graphs.\n",
      "Thresholds A (atomic number): [0. 1. 6.]\n",
      "Thresholds B (degree): [1. 2. 3. 4.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing multipersistence surfaces: 100%|███████████████████████████████████████████| 188/188 [00:24<00:00,  7.65it/s]\n",
      "C:\\DevTools\\Projects\\topo-ml\\gtda_env\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [11:21:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESULTS ===\n",
      "Accuracy: 0.8771929824561403\n",
      "Balanced Accuracy: 0.881578947368421\n",
      "ROC AUC: 0.9030470914127423\n",
      "Confusion matrix:\n",
      " [[17  2]\n",
      " [ 5 33]]\n"
     ]
    }
   ],
   "source": [
    "# multipersistence_mutag.py\n",
    "# Multipersistence snapshot (2-parameter) pipeline for MUTAG:\n",
    "#  - parameter A: atomic number (node attribute)\n",
    "#  - parameter B: node degree (computed on original graph)\n",
    "#  - compute Betti (0,1,2) at each (eps_A, eps_B) grid point\n",
    "#  - vectorize surfaces, train XGBoost, report metrics\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, roc_auc_score, confusion_matrix\n",
    "import xgboost as xgb\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import pyflagser\n",
    "\n",
    "# -------------------------\n",
    "# User-tunable settings\n",
    "# -------------------------\n",
    "N_THRESH_A = 6   # number of thresholds along parameter A (atomic number)\n",
    "N_THRESH_B = 6   # number of thresholds along parameter B (degree)\n",
    "USE_QUANTILES = True  # use quantile-based thresholds across dataset (recommended)\n",
    "MIN_DIM = 0\n",
    "MAX_DIM = 2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# -------------------------\n",
    "# Helper functions\n",
    "# -------------------------\n",
    "def graph_from_pyg_data(data):\n",
    "    \"\"\"\n",
    "    Build networkx graph and attach atomic_number attribute if available.\n",
    "    Fallbacks: data.x (single scalar or one-hot -> argmax), data.z\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "    n = data.num_nodes\n",
    "    for i in range(n):\n",
    "        G.add_node(i)\n",
    "    edge_index = data.edge_index.numpy()\n",
    "    for u, v in edge_index.T:\n",
    "        G.add_edge(int(u), int(v))\n",
    "\n",
    "    # try to extract node scalar labels / atomic numbers\n",
    "    atomic_numbers = None\n",
    "    if hasattr(data, 'x') and data.x is not None:\n",
    "        x_np = data.x.numpy()\n",
    "        if x_np.ndim == 1 or (x_np.ndim == 2 and x_np.shape[1] == 1):\n",
    "            atomic_numbers = x_np.reshape(-1)\n",
    "        elif x_np.ndim == 2:\n",
    "            # assume one-hot -> argmax label\n",
    "            atomic_numbers = np.argmax(x_np, axis=1)\n",
    "    if atomic_numbers is None and hasattr(data, 'z'):\n",
    "        atomic_numbers = data.z.numpy().reshape(-1)\n",
    "    if atomic_numbers is None:\n",
    "        atomic_numbers = np.zeros(n, dtype=float)\n",
    "\n",
    "    for i, val in enumerate(atomic_numbers):\n",
    "        G.nodes[i]['atomic_number'] = float(val)\n",
    "\n",
    "    # also attach original degree (on full graph) as a separate node attribute\n",
    "    for i in G.nodes():\n",
    "        G.nodes[i]['orig_degree'] = float(G.degree(i))\n",
    "\n",
    "    return G\n",
    "\n",
    "def compute_betti_numbers_for_active(active_nodes, full_graph):\n",
    "    \"\"\"\n",
    "    Given list of active node indices and the full graph (networkx),\n",
    "    compute Betti numbers up to MAX_DIM using pyflagser.flagser_unweighted.\n",
    "    \"\"\"\n",
    "    if len(active_nodes) == 0:\n",
    "        return (0, 0, 0)\n",
    "    H = full_graph.subgraph(sorted(active_nodes)).copy()\n",
    "    nodelist = sorted(H.nodes())\n",
    "    if len(nodelist) == 0:\n",
    "        return (0, 0, 0)\n",
    "    Adj = nx.to_numpy_array(H, nodelist=nodelist)\n",
    "    my_flag = pyflagser.flagser_unweighted(\n",
    "        Adj, min_dimension=MIN_DIM, max_dimension=MAX_DIM,\n",
    "        directed=False, coeff=2, approximation=None\n",
    "    )\n",
    "    x = my_flag.get(\"betti\", [])\n",
    "    b0 = int(x[0]) if len(x) > 0 else 0\n",
    "    b1 = int(x[1]) if len(x) > 1 else 0\n",
    "    b2 = int(x[2]) if len(x) > 2 else 0\n",
    "    return (b0, b1, b2)\n",
    "\n",
    "def build_thresholds(values, n_thresholds, use_quantiles=True):\n",
    "    \"\"\"\n",
    "    Build sorted unique threshold array for given values across dataset.\n",
    "    \"\"\"\n",
    "    vals = np.asarray(values)\n",
    "    if vals.size == 0:\n",
    "        return np.array([0.0])\n",
    "    if use_quantiles:\n",
    "        qs = np.linspace(0.0, 1.0, n_thresholds)\n",
    "        thr = np.quantile(vals, qs)\n",
    "    else:\n",
    "        thr = np.linspace(vals.min(), vals.max(), n_thresholds)\n",
    "    return np.unique(thr)\n",
    "\n",
    "def vectorize_betti_surfaces(betti0, betti1, betti2):\n",
    "    \"\"\"\n",
    "    Vectorize 2D Betti surfaces into 1D feature vector.\n",
    "    Strategy:\n",
    "      - flatten each surface (row-major)\n",
    "      - append summary stats (mean, max, sum, variance) per dimension\n",
    "    \"\"\"\n",
    "    f = []\n",
    "    for surf in (betti0, betti1, betti2):\n",
    "        flat = surf.flatten()\n",
    "        f.extend(flat.tolist())\n",
    "        # basic summaries\n",
    "        f.append(np.mean(flat))\n",
    "        f.append(np.max(flat))\n",
    "        f.append(np.sum(flat))\n",
    "        f.append(np.var(flat))\n",
    "    return np.array(f, dtype=float)\n",
    "\n",
    "# -------------------------\n",
    "# Main pipeline\n",
    "# -------------------------\n",
    "def main():\n",
    "    # Load MUTAG\n",
    "    dataset = TUDataset(root='data/TUDataset', name='MUTAG')\n",
    "    print(f\"Loaded MUTAG with {len(dataset)} graphs.\")\n",
    "\n",
    "    graphs = []\n",
    "    labels = []\n",
    "    all_atomic_vals = []\n",
    "    all_degree_vals = []\n",
    "\n",
    "    # convert and collect global distributions\n",
    "    for data in dataset:\n",
    "        G = graph_from_pyg_data(data)\n",
    "        graphs.append(G)\n",
    "        labels.append(int(data.y.item()))\n",
    "        all_atomic_vals.extend([G.nodes[n]['atomic_number'] for n in G.nodes()])\n",
    "        all_degree_vals.extend([G.nodes[n]['orig_degree'] for n in G.nodes()])\n",
    "\n",
    "    # Build thresholds for both parameters\n",
    "    thr_A = build_thresholds(all_atomic_vals, N_THRESH_A, use_quantiles=USE_QUANTILES)\n",
    "    thr_B = build_thresholds(all_degree_vals, N_THRESH_B, use_quantiles=USE_QUANTILES)\n",
    "    print(\"Thresholds A (atomic number):\", thr_A)\n",
    "    print(\"Thresholds B (degree):\", thr_B)\n",
    "\n",
    "    features = []\n",
    "    for G in tqdm(graphs, desc=\"Computing multipersistence surfaces\"):\n",
    "        # For each graph build 2D Betti surfaces sized (len(thr_A), len(thr_B))\n",
    "        nA = len(thr_A)\n",
    "        nB = len(thr_B)\n",
    "        betti0_surf = np.zeros((nA, nB), dtype=int)\n",
    "        betti1_surf = np.zeros((nA, nB), dtype=int)\n",
    "        betti2_surf = np.zeros((nA, nB), dtype=int)\n",
    "\n",
    "        # prefetch node attribute dicts\n",
    "        node_atomic = {n: G.nodes[n].get('atomic_number', 0.0) for n in G.nodes()}\n",
    "        node_degree = {n: G.nodes[n].get('orig_degree', float(G.degree(n))) for n in G.nodes()}\n",
    "\n",
    "        for iA, a_eps in enumerate(thr_A):\n",
    "            for iB, b_eps in enumerate(thr_B):\n",
    "                # sublevel-sublevel: nodes with atomic <= a_eps AND degree <= b_eps\n",
    "                active_nodes = [n for n in G.nodes() if (node_atomic[n] <= a_eps and node_degree[n] <= b_eps)]\n",
    "                b0, b1, b2 = compute_betti_numbers_for_active(active_nodes, G)\n",
    "                betti0_surf[iA, iB] = b0\n",
    "                betti1_surf[iA, iB] = b1\n",
    "                betti2_surf[iA, iB] = b2\n",
    "\n",
    "        # vectorize surfaces into fixed-size feature vector\n",
    "        feat = vectorize_betti_surfaces(betti0_surf, betti1_surf, betti2_surf)\n",
    "        features.append(feat)\n",
    "\n",
    "    X = np.vstack(features)\n",
    "    y = np.array(labels)\n",
    "\n",
    "    # Train/test split and XGBoost classifier\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "    clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=RANDOM_STATE)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    # handle binary or multi-class probability extraction safely\n",
    "    try:\n",
    "        if clf.n_classes_ > 1:\n",
    "            y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "        else:\n",
    "            y_proba = clf.predict_proba(X_test)[:, 0]\n",
    "    except Exception:\n",
    "        y_proba = None\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_proba) if (y_proba is not None and len(np.unique(y_test)) == 2) else None\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(\"=== RESULTS ===\")\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Balanced Accuracy:\", bal_acc)\n",
    "    print(\"ROC AUC:\", roc)\n",
    "    print(\"Confusion matrix:\\n\", cm)\n",
    "\n",
    "    # return useful objects for inspection/visualization\n",
    "    return {\n",
    "        \"model\": clf,\n",
    "        \"thr_A\": thr_A,\n",
    "        \"thr_B\": thr_B,\n",
    "        \"X\": X,\n",
    "        \"y\": y\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    res = main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (gtda_env)",
   "language": "python",
   "name": "gtda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
